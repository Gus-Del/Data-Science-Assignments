{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEo8tS1yejNp/B4BfkhRjp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FJio17n9cLao"},"outputs":[],"source":["# axis=1, means columns. and axis=0 means rows.\n","# Unstack the first level and calculate the mean of the columns\n","obesity_general = obesity.unstack(level=0).mean(axis=1)\n","\n","# Unstack the second level and calculate the mean of the columns\n","obesity_mean = obesity.unstack(level=1).mean(axis=1)\n","\n","# Unstack the third level and calculate the difference between columns\n","obesity_variation = obesity.unstack(level=2).diff(axis=1)\n","\n","# Stack obesity, get median of columns and unstack again\n","median_obesity = obesity.stack().median(axis=1).unstack()\n","\n","# Stack the first level, get sum, and unstack the second level\n","obesity_sum = obesity.stack(level=0).sum(axis=1).unstack(level=1)\n","\n","# Stack country level, group by country and get the mean\n","obesity_mean = obesity.stack(level='country').groupby('country').mean()\n","\n","# Stack country level, group by country and get the median\n","obesity_median = obesity.stack(level='country').groupby('country').median()\n"]},{"cell_type":"markdown","source":["Transforming a list-like Column"],"metadata":{"id":"m_XFYUw9eT8W"}},{"cell_type":"code","source":["# Explode the values of bounds to a separate row\n","obesity_bounds = obesity['bounds'].explode()\n","\n","# Print obesity_bounds\n","print(obesity_bounds)"],"metadata":{"id":"V7vvQlPGeYQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge obesity_bounds with country and perc_obesity columns of obesity using the indexes\n","obesity_final = obesity[['country','perc_obesity']].merge(obesity_bounds,\n","                                        right_index=True,\n","                                        left_index=True)\n","\n","# Transform the list-like column named bounds\n","obesity_explode = obesity.explode(['bounds'])\n","\n","# Modify obesity_explode by resetting the index\n","obesity_explode.reset_index(drop=True, inplace=True)\n","\n","# Print obesity_explode\n","print(obesity_explode)\n","<script.py> output:\n","         country  perc_obesity bounds\n","    0  Argentina          21.5   15.4\n","    1  Argentina          21.5   31.5\n","    2    Germany          22.3   16.2\n","    3    Germany          22.3   32.4\n","    4      Japan           2.5    1.1\n","    5      Japan           2.5    3.5\n","    6     Norway          23.0   13.1\n","    7     Norway          23.0   33.0\n","\n","# Split the columns bounds using a hyphen as delimiter\n","obesity_split = obesity['bounds'].str.split('-')\n","\n","# Print obesity_split\n","print(obesity_split)\n","\n","# Assign the result of the split to the bounds column\n","obesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-'))\n","\n","# Print obesity\n","print(obesity_split)\n","\n","# Transform the column bounds in the obesity DataFrame\n","obesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-')).explode('bounds')\n","\n","# Print obesity_split\n","print(obesity_split)\n","\n"],"metadata":{"id":"TjDSmuuou7Li"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reading nested data into a DataFrame."],"metadata":{"id":"_SxDS3Ek5bfY"}},{"cell_type":"code","source":["# Import the json_normalize function\n","from pandas import json_normalize\n","\n","# Normalize movies and separate the new columns with an underscore\n","movies_norm = json_normalize(movies, sep='_')\n","\n","# Reshape using director and producer as index, create movies from column starting from features\n","movies_long = pd.wide_to_long(movies_norm, stubnames= ['features'],\n","                      i=['director','producer'], j='movies',\n","                      sep='_', suffix='\\w+')\n","\n","# Print movies_long\n","print(movies_long)\n","\n","# Normalize the JSON contained in movies\n","normalize_movies = json_normalize(movies)\n","\n","# Print normalize_movies\n","print(normalize_movies)\n","\n","# Specify the features column as the list of records\n","normalize_movies = json_normalize(movies,\n","                                  record_path='features')\n","\n","# Print normalize_movies\n","print(normalize_movies)\n","\n","# Specify director and producer to use as metadata for each record\n","normalize_movies = json_normalize(movies,\n","                                  record_path='features',\n","                                  meta=['director','producer'])\n","\n","# Print normalize_movies\n","print(normalize_movies)\n","\n","# Define birds reading names and bird_facts lists into names and bird_facts columns\n","birds = pd.DataFrame(dict(names=names, bird_facts=bird_facts))\n","\n","# Print birds\n","print(birds)\n","\n","\n","# Apply the function json.loads function to the bird_facts column\n","data_split = birds['bird_facts'].apply(json.loads).apply(pd.Series)\n","\n","# Remove the bird_facts column from birds\n","birds = birds.drop( columns ='bird_facts')\n","\n","# Concatenate the columns of birds and data_split\n","birds = pd.concat([birds, data_split], axis=1)\n","\n","# Apply json.loads to the bird_facts column and transform it to a list\n","birds_facts = birds['bird_facts'].apply(json.loads).explode()\n","\n","# Print birds_facts\n","print(birds_facts)\n","\n","# Apply json.loads to the bird_facts column and transform it to a list\n","birds_facts = birds['bird_facts'].apply(json.loads).to_list()\n","\n","# Convert birds_facts into a JSON\n","birds_dump = json.dumps(birds_facts)\n","\n","# Read the JSON birds_dump into a DataFrame\n","birds_df = pd.read_json(birds_dump)\n","\n","# Concatenate the 'names' column of birds with birds_df\n","birds_final = pd.concat([birds['names'], birds_df], axis=1)"],"metadata":{"id":"sa6IBOH85fXm"},"execution_count":null,"outputs":[]}]}